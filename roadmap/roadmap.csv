Week,Topics/Architectures,Learning Resources,Implementation Tasks,Time Breakdown,Milestones
1,"Basics: Single neuron, Perceptron, MLP fundamentals",Neural Networks from Scratch (Kinsley & Kukiela) Ch. 1-3; Andrew Ng's Coursera ML course (Week 4 on NNs),"Implement a single-layer perceptron for binary classification (e.g., XOR); Build forward pass and basic gradient descent",Study: 4h; Code: 6h; Test: 4h,Working perceptron on toy dataset; understand matrix operations in NumPy
2,"Multi-Layer Perceptrons (MLPs): Vanilla MLP, handling multi-class","Same book, Ch. 4-6; Deep Learning (Goodfellow et al.) Ch. 6","Implement a 3-layer MLP from scratch (forward/backprop); Add activations, dropout, and batch normalization",Study: 4h; Code: 7h; Test: 3h,Train MLP on MNIST; achieve >90% accuracy
3,"Advanced MLPs: Variants with regularization, optimizers",PyTorch tutorials on custom autograd (but implement manually first); Paper: A Neural Algorithm of Artistic Style,Extend MLP with L1/L2 regularization and Adam optimizer; Experiment with hyperparams on Iris/Fashion-MNIST,Study: 3h; Code: 8h; Test: 3h,Optimized MLP; compare vanilla vs. advanced on validation sets
4,CNN Basics: LeNet-5 for digit recognition,Deep Learning Ch. 9; Original LeNet paper (LeCun 1998),"Implement convolution/pooling layers from scratch; Build LeNet-5 (conv, pool, FC layers)",Study: 5h; Code: 6h; Test: 3h,LeNet on MNIST; visualize filters
5,Classic CNNs: AlexNet for image classification,AlexNet paper (Krizhevsky 2012); CS231n Stanford notes on CNNs,"Add data augmentation, ReLU, dropout to CNN base; Implement AlexNet (8 layers, overlapping pooling)",Study: 4h; Code: 7h; Test: 3h,AlexNet on CIFAR-10; >70% accuracy
6,"Object Detection CNNs: R-CNN family (R-CNN, Fast R-CNN)","R-CNN paper (Girshick 2014), Fast R-CNN (2015); PyImageSearch tutorials",Implement selective search for regions; Build basic R-CNN: CNN feature extractor + SVM classifier,Study: 5h; Code: 7h; Test: 3h,"Detect objects on small dataset (e.g., Pascal VOC); mAP metric"
7,"Advanced CNNs: Faster R-CNN, VGG/ResNet intro",Faster R-CNN paper (Ren 2015); VGG/ResNet papers,Add Region Proposal Network (RPN) to Fast R-CNN; Implement a mini-VGG or ResNet block (residual connections),Study: 4h; Code: 8h; Test: 3h,Faster R-CNN on custom images; understand skip connections
8,RNN Basics: Vanilla RNN for sequences,Deep Learning Ch. 10; Colah's LSTM blog post (intro to RNNs),Implement RNN cell (forward/recurrent); Train on sine wave prediction or IMDB sentiment,Study: 5h; Code: 6h; Test: 3h,RNN handling vanishing gradients; basic sequence gen
9,LSTMs and GRUs: Handling long dependencies,"LSTM paper (Hochreiter 1997), GRU (Cho 2014); Karpathy's RNN blog","Build LSTM gates (forget, input, output); Implement bidirectional LSTM and GRU variant",Study: 4h; Code: 7h; Test: 3h,"LSTM on text generation (e.g., Shakespeare); compare to vanilla RNN"
10,"Other Sequential: Seq2Seq, Attention basics",Seq2Seq paper (Sutskever 2014); Attention paper (Bahdanau 2014),Implement encoder-decoder for machine translation; Add basic attention mechanism to RNN,Study: 5h; Code: 7h; Test: 3h,Seq2Seq on simple translation task; visualize attention weights
11,Autoencoders: Vanilla and Denoising,Deep Learning Ch. 14; Autoencoder tutorial on Towards Data Science,Implement encoder-decoder with bottleneck; Add noise for denoising variant; reconstruct images,Study: 4h; Code: 6h; Test: 4h,Autoencoder on MNIST; low reconstruction error
12,VAEs and Advanced Autoencoders: Variational Autoencoders,VAE paper (Kingma 2013); Pyro/PyTorch VAE examples (manual impl),Add KL divergence and reparameterization trick; Generate new samples from latent space,Study: 5h; Code: 7h; Test: 3h,VAE generating digits; understand probabilistic encoding
13,"GANs: Vanilla GAN, DCGAN","Original GAN paper (Goodfellow 2014), DCGAN (Radford 2015); GANs from Scratch tutorials",Implement discriminator/generator adversarial training; Add conv layers for DCGAN on images,Study: 5h; Code: 7h; Test: 3h,GAN generating fake MNIST; stable training (mode collapse checks)
14,"Advanced GANs: WGAN, CycleGAN","WGAN paper (Arjovsky 2017), CycleGAN (Zhu 2017); Hands-on GAN repos on GitHub",Modify loss to Wasserstein; clip weights; Implement unpaired image-to-image translation,Study: 4h; Code: 8h; Test: 3h,"CycleGAN for style transfer (e.g., horse-to-zebra); evaluate FID score"
15,"Transformers Basics: Self-Attention, Multi-Head",Attention Is All You Need paper (Vaswani 2017); Illustrated Transformer blog (Jay Alammar),Implement positional encoding and self-attention; Build a single Transformer layer,Study: 6h; Code: 6h; Test: 3h,Attention on toy sequence; visualize matrices
16,"Full Transformers: Encoder-Decoder (e.g., BERT-like, GPT-like)","BERT paper (Devlin 2018), GPT (Radford 2018); Hugging Face from-scratch guides (but manual)",Stack layers for encoder (masked LM); Implement decoder for autoregressive generation,Study: 5h; Code: 7h; Test: 3h,Mini-BERT pretraining on text; fine-tune for classification
17,"Variants: Vision Transformer (ViT), T5","ViT paper (Dosovitskiy 2020), T5 (Raffel 2019); ViT tutorials",Patchify images for ViT; Add text-to-text framework for T5-like,Study: 4h; Code: 8h; Test: 3h,ViT on CIFAR; generate text with decoder
18,GNN Basics: Graph Convolutional Networks (GCN),GCN paper (Kipf 2016); PyG (PyTorch Geometric) docs (but implement core manually),Represent graphs (adjacency matrix); Implement message passing and aggregation,Study: 5h; Code: 6h; Test: 3h,GCN node classification on Cora; accuracy >80%
19,"Advanced GNNs: Graph Attention (GAT), GraphSAGE","GAT paper (Velickovic 2017), GraphSAGE (Hamilton 2017); DGL library tutorials (manual impl)",Add attention to graph conv; Implement inductive learning for new nodes,Study: 4h; Code: 7h; Test: 3h,GAT on link prediction; handle large graphs
20,"Other Models: Diffusion Models, SOM, Boltzmann Machines","Diffusion paper (Ho 2020), SOM (Kohonen); Grokking Deep Learning for extras",Implement forward/reverse diffusion process; Build basic SOM for clustering; restricted Boltzmann for collab filtering,Study: 5h; Code: 7h; Test: 3h,Diffusion generating images; SOM visualization; capstone project integrating models
